{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Translation Demo 3.2. Evaluation Bidirectional.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNWdrolyqvSgttHF+GKqtKq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bAK5iHy80ZQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873516490,"user_tz":-180,"elapsed":7256,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"6dd7896f-8236-4e6e-98ad-e8fb5f8f5d02"},"source":["%tensorflow_version 1.x\n","\n","import pickle as pkl\n","import numpy as np\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from nltk.translate.gleu_score import corpus_gleu\n","\n","import tensorflow.python.keras.backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ACevsnNFA1TU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873536663,"user_tz":-180,"elapsed":27420,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"929e0572-3d64-4510-8945-124864e1d91d"},"source":["# Imports for colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dirname = '/content/gdrive/My Drive/Colab Notebooks/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RG06b_PbJhtg"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"m0GlKh3DBDi6"},"source":["## Load clean datasets and tokenizers"]},{"cell_type":"code","metadata":{"id":"zW6TU4P0AGqY","executionInfo":{"status":"ok","timestamp":1612873536664,"user_tz":-180,"elapsed":27414,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def load_pickle(filename):\n","    return pkl.load(open(filename, 'rb'))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMuKN-hqBnq3"},"source":["## Compute max length of sentence"]},{"cell_type":"code","metadata":{"id":"SCIQDZu6Bksw","executionInfo":{"status":"ok","timestamp":1612873536665,"user_tz":-180,"elapsed":27409,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def max_length(lines):\n","\treturn max(len(line.split()) for line in lines)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRivrL77BtI3"},"source":["## Encode and pad sequences"]},{"cell_type":"code","metadata":{"id":"Hy74uoFxBpvG","executionInfo":{"status":"ok","timestamp":1612873536667,"user_tz":-180,"elapsed":27407,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def encode_sequences(tokenizer, length, lines):\n","    # Encode sequences\n","    X = tokenizer.texts_to_sequences(lines)\n","\n","    # Pad sequences with zeros\n","    X = pad_sequences(X, maxlen=length, padding='post')\n","\n","    return X"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cUj8IbOFWeF"},"source":["## Generate a translation from a sequence\n","Algorithm predicts a one-hot encodings of words in a batch of sentences, which can be converted to sequences of numbers of words in a dictionary, which eventually will be converted to sequences of words"]},{"cell_type":"code","metadata":{"id":"4MA2-1FqBvjX","executionInfo":{"status":"ok","timestamp":1612873536668,"user_tz":-180,"elapsed":27403,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def batch_generator(sources, batch_size):\n","    for i in range(0, sources.shape[0], batch_size):\n","        yield sources[i:i + batch_size, :]\n","\n","def predict_texts(model, tokenizer, sources, batch_size=4096):\n","    integers = np.empty((sources.shape[0], model.layers[-1].output_shape[1]))\n","    if batch_size==None:\n","        predictions = model.predict(sources, verbose=0, use_multiprocessing=True)\n","        integers = np.argmax(predictions, axis=2)\n","    else:\n","        for idx, batch in enumerate(batch_generator(sources, batch_size)):\n","            actual_batch_len = batch.shape[0]\n","            predictions = model.predict(batch, verbose=0, use_multiprocessing=True)\n","            integers[idx*batch_size:idx*batch_size + actual_batch_len] = np.argmax(predictions, axis=2)\n","    target = tokenizer.sequences_to_texts(integers)\n","    return target"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEwSSPEDJeoR"},"source":["## Evaluate the model"]},{"cell_type":"code","metadata":{"id":"O7CquIilGmRn","executionInfo":{"status":"ok","timestamp":1612873536669,"user_tz":-180,"elapsed":27400,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def evaluate_model(model, tokenizer, sources, raw_dataset, batch_size=4096):\n","    actual = [raw_target.split() for raw_target in raw_dataset[:, 1]]\n","    predicted = predict_texts(model, tokenizer, sources, batch_size)\n","    print('Predictions are done. Calculating the scores now')\n","    predicted = [text.split() for text in predicted]\n","    for i in range(10):\n","        print('src=[%s], target=[%s], predicted=[%s]' % (raw_dataset[i, 0], raw_dataset[i, 1], ' '.join(predicted[i])))\n","    # Calculate BLEU score. n-gram (n is up to 4) count weights are 0.25\n","    smoothing = SmoothingFunction()\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, smoothing_function=smoothing.method4))\n","    # Calculate GLEU score. Maximum n-gram length count - 4\n","    print('GLEU-4: %f' % corpus_gleu(actual, predicted))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tl0O4nsYOTPw"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"R56c_YdmMEe7","executionInfo":{"status":"ok","timestamp":1612873541357,"user_tz":-180,"elapsed":32083,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["# Load datasets\n","dataset = load_pickle(dirname + 'english-russian-100k-both.pkl')\n","train = load_pickle(dirname + 'english-russian-100k-train.pkl')\n","test = load_pickle(dirname + 'english-russian-100k-test.pkl')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq7arF4mOb1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873541933,"user_tz":-180,"elapsed":32653,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"4cb52399-f4a7-4e51-a0b0-d2f657b5b500"},"source":["# Prepare english tokenizer\n","eng_tokenizer = load_pickle(dirname + 'en_tokenizer_100k')\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1 #+1 because of <EOS> token\n","eng_length = max_length(dataset[:, 0])\n","print('English vocabulary size: %d' % eng_vocab_size)\n","print('English max sentence length: %d' % eng_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["English vocabulary size: 7313\n","English max sentence length: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O_l51gJkO0lu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873542190,"user_tz":-180,"elapsed":32903,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"5d2c54e2-e9bf-402d-b932-5efc22c3cde2"},"source":["# Prepare russian tokenizer\n","rus_tokenizer = load_pickle(dirname + 'ru_tokenizer_100k')\n","rus_vocab_size = len(rus_tokenizer.word_index) + 1\n","rus_length = max_length(dataset[:, 1])\n","print('Russian vocabulary size: %d' % rus_vocab_size)\n","print('Russian max sentence length: %d' % rus_length)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Russian vocabulary size: 20884\n","Russian max sentence length: 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpmtW6r4O1RW","executionInfo":{"status":"ok","timestamp":1612873543955,"user_tz":-180,"elapsed":34628,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["#Encode sequences\n","X_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n","X_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3l8mrInPEKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873557456,"user_tz":-180,"elapsed":47723,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"2c4dd8e1-4b4b-4357-a69e-a75920625ea0"},"source":["# Load model\n","K.clear_session()\n","model = load_model(dirname + 'model_bidirectional_100k_100e.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8oQLLV-PJnO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873678108,"user_tz":-180,"elapsed":167458,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"c0000761-9628-48e2-bfe8-087078d4b7a1"},"source":["# Evaluation on training sequences\n","print('Train:')\n","evaluate_model(model, rus_tokenizer, X_train, train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train:\n","Predictions are done. Calculating the scores now\n","src=[i buried it], target=[я её закопал], predicted=[я её закопал]\n","src=[go and wake up mary], target=[пойди разбуди мэри], predicted=[пойди разбуди мэри]\n","src=[she did a good job], target=[она проделала хорошую работу], predicted=[она проделала хорошую работу]\n","src=[i work at a zoo], target=[я работаю в зоопарке], predicted=[я работаю в зоопарке]\n","src=[i want them], target=[я хочу их], predicted=[я хочу хочу]\n","src=[ive been thinking], target=[я размышляю], predicted=[я размышляю]\n","src=[we talked about boys], target=[мы говорили о мальчиках], predicted=[мы говорили о мальчиках]\n","src=[is that blood], target=[это кровь], predicted=[это кровь]\n","src=[dont be so selfish], target=[не будь такой эгоисткой], predicted=[не будьте таким эгоистками]\n","src=[people are stupid], target=[люди глупы], predicted=[люди глупы]\n","BLEU-4: 0.012202\n","GLEU-4: 0.027930\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bnJR07DLRu9w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873691406,"user_tz":-180,"elapsed":180174,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"bf39a2aa-111e-4fb9-dcb5-f24b4091aa35"},"source":["# Evaluation on test sequences\n","print('Test:')\n","evaluate_model(model, rus_tokenizer, X_test, test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Test:\n","Predictions are done. Calculating the scores now\n","src=[tom is very good], target=[том очень хороший], predicted=[том очень хороший]\n","src=[i was born in 1960], target=[я родился в 1960], predicted=[я родилась в в в]\n","src=[do you work in boston], target=[вы работаете в бостоне], predicted=[ты работаешь в бостоне]\n","src=[look at this picture], target=[посмотрите на эту картинку], predicted=[посмотрите на эту картинку]\n","src=[theres a problem], target=[есть проблема], predicted=[проблема проблема проблема]\n","src=[tom is my neighbor], target=[том  мой сосед], predicted=[том мой мой]\n","src=[wasnt he your friend], target=[он разве не был тебе другом], predicted=[он был не друг друг]\n","src=[i was playing here], target=[я здесь играл], predicted=[я играла здесь]\n","src=[its good to dream], target=[мечтать хорошо], predicted=[это трудно]\n","src=[come by tomorrow], target=[заходи завтра], predicted=[приходите завтра завтра]\n","BLEU-4: 0.148913\n","GLEU-4: 0.026432\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iun6XKBqukxM"},"source":[""],"execution_count":null,"outputs":[]}]}