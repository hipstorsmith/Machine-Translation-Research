{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Translation Demo 3.3. Evaluation Deep Models.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP+/ADNWQPiuIIx2pMV+1n+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bAK5iHy80ZQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873946974,"user_tz":-180,"elapsed":2745,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"3375daf1-2129-4b21-fb72-b6c854984d33"},"source":["%tensorflow_version 1.x\n","\n","import pickle as pkl\n","import numpy as np\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from nltk.translate.gleu_score import corpus_gleu\n","\n","import tensorflow.python.keras.backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ACevsnNFA1TU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873946975,"user_tz":-180,"elapsed":2738,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"cfca9dd0-61ab-41ca-bf46-1c1d1e9772dd"},"source":["# Imports for colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dirname = '/content/gdrive/My Drive/Colab Notebooks/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RG06b_PbJhtg"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"m0GlKh3DBDi6"},"source":["## Load clean dataset"]},{"cell_type":"code","metadata":{"id":"zW6TU4P0AGqY","executionInfo":{"status":"ok","timestamp":1612873946975,"user_tz":-180,"elapsed":2733,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def load_pickle(filename):\n","    return pkl.load(open(filename, 'rb'))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMuKN-hqBnq3"},"source":["## Compute max length of sentence"]},{"cell_type":"code","metadata":{"id":"SCIQDZu6Bksw","executionInfo":{"status":"ok","timestamp":1612873946976,"user_tz":-180,"elapsed":2730,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def max_length(lines):\n","    return max(len(line.split()) for line in lines)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRivrL77BtI3"},"source":["## Encode and pad sequences"]},{"cell_type":"code","metadata":{"id":"Hy74uoFxBpvG","executionInfo":{"status":"ok","timestamp":1612873946977,"user_tz":-180,"elapsed":2729,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def encode_sequences(tokenizer, length, lines):\n","    # Encode sequences\n","    X = tokenizer.texts_to_sequences(lines)\n","\n","    # Pad sequences with zeros\n","    X = pad_sequences(X, maxlen=length, padding='post')\n","\n","    return X"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cUj8IbOFWeF"},"source":["## Generate a translation from a sequence\n","Algorithm predicts a one-hot encodings of words in a batch of sentences, which can be converted to sequences of numbers of words in a dictionary, which eventually will be converted to sequences of words"]},{"cell_type":"code","metadata":{"id":"4MA2-1FqBvjX","executionInfo":{"status":"ok","timestamp":1612873946977,"user_tz":-180,"elapsed":2726,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def batch_generator(sources, batch_size):\n","    for i in range(0, sources.shape[0], batch_size):\n","        yield sources[i:i + batch_size, :]\n","\n","def predict_texts(model, tokenizer, sources, batch_size=4096):\n","    integers = np.empty((sources.shape[0], model.layers[-1].output_shape[1]))\n","    if batch_size==None:\n","        predictions = model.predict(sources, verbose=0, use_multiprocessing=True)\n","        integers = np.argmax(predictions, axis=2)\n","    else:\n","        for idx, batch in enumerate(batch_generator(sources, batch_size)):\n","            actual_batch_len = batch.shape[0]\n","            predictions = model.predict(batch, verbose=0, use_multiprocessing=True)\n","            integers[idx*batch_size:idx*batch_size + actual_batch_len] = np.argmax(predictions, axis=2)\n","    target = tokenizer.sequences_to_texts(integers)\n","    return target"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEwSSPEDJeoR"},"source":["## Evaluate the model"]},{"cell_type":"code","metadata":{"id":"O7CquIilGmRn","executionInfo":{"status":"ok","timestamp":1612873946978,"user_tz":-180,"elapsed":2723,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def evaluate_model(model, tokenizer, sources, raw_dataset, batch_size=4096):\n","    actual = [raw_target.split() for raw_target in raw_dataset[:, 1]]\n","    predicted = predict_texts(model, tokenizer, sources, batch_size)\n","    print('Predictions are done. Calculating the scores now')\n","    predicted = [text.split() for text in predicted]\n","    for i in range(10):\n","        print('src=[%s], target=[%s], predicted=[%s]' % (raw_dataset[i, 0], raw_dataset[i, 1], ' '.join(predicted[i])))\n","    # Calculate BLEU score. n-gram (n is up to 4) count weights are 0.25\n","    smoothing = SmoothingFunction()\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, smoothing_function=smoothing.method5))\n","    # Calculate GLEU score. Maximum n-gram length count - 4\n","    print('GLEU-4: %f' % corpus_gleu(actual, predicted))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tl0O4nsYOTPw"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"R56c_YdmMEe7","executionInfo":{"status":"ok","timestamp":1612873951140,"user_tz":-180,"elapsed":6883,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["# Load datasets\n","dataset = load_pickle(dirname + 'english-russian-100k-both.pkl')\n","train = load_pickle(dirname + 'english-russian-100k-train.pkl')\n","test = load_pickle(dirname + 'english-russian-100k-test.pkl')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq7arF4mOb1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873951666,"user_tz":-180,"elapsed":7406,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"fffddc9c-3b0a-4297-ca40-ce661fafc892"},"source":["# Prepare english tokenizer\n","eng_tokenizer = load_pickle(dirname + 'en_tokenizer_100k')\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1 #+1 because of <EOS> token\n","eng_length = max_length(dataset[:, 0])\n","print('English vocabulary size: %d' % eng_vocab_size)\n","print('English max sentence length: %d' % eng_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["English vocabulary size: 7313\n","English max sentence length: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O_l51gJkO0lu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873952099,"user_tz":-180,"elapsed":7834,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"39c84305-6f1b-4ff3-eacd-8960e86bb1da"},"source":["# Prepare russian tokenizer\n","rus_tokenizer = load_pickle(dirname + 'ru_tokenizer_100k')\n","rus_vocab_size = len(rus_tokenizer.word_index) + 1\n","rus_length = max_length(dataset[:, 1])\n","print('Russian vocabulary size: %d' % rus_vocab_size)\n","print('Russian max sentence length: %d' % rus_length)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Russian vocabulary size: 20884\n","Russian max sentence length: 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpmtW6r4O1RW","executionInfo":{"status":"ok","timestamp":1612873953414,"user_tz":-180,"elapsed":9144,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["#Encode sequences\n","X_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n","X_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3l8mrInPEKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612873964613,"user_tz":-180,"elapsed":20339,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"3e1d73e4-db62-4a1c-da32-2eeb0d18ac06"},"source":["# Load model\n","K.clear_session()\n","model = load_model(dirname + 'model_deep_dropout_100k_100e.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8oQLLV-PJnO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874110030,"user_tz":-180,"elapsed":165752,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"a19200ed-e771-4bf7-f1e6-9c8b0122232f"},"source":["# Evaluation on training sequences\n","print('Train:')\n","evaluate_model(model, rus_tokenizer, X_train, train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train:\n","Predictions are done. Calculating the scores now\n","src=[i buried it], target=[я её закопал], predicted=[я её закопал]\n","src=[go and wake up mary], target=[пойди разбуди мэри], predicted=[пойди разбуди мэри]\n","src=[she did a good job], target=[она проделала хорошую работу], predicted=[она проделала хорошую работу]\n","src=[i work at a zoo], target=[я работаю в зоопарке], predicted=[я работаю в зоопарке]\n","src=[i want them], target=[я хочу их], predicted=[я их их]\n","src=[ive been thinking], target=[я размышляю], predicted=[я думаю]\n","src=[we talked about boys], target=[мы говорили о мальчиках], predicted=[мы говорили о мальчиках]\n","src=[is that blood], target=[это кровь], predicted=[это кровь]\n","src=[dont be so selfish], target=[не будь такой эгоисткой], predicted=[не будь таким эгоисткой]\n","src=[people are stupid], target=[люди глупы], predicted=[люди глупы]\n","BLEU-4: 0.075211\n","GLEU-4: 0.027631\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bnJR07DLRu9w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874126075,"user_tz":-180,"elapsed":181793,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"f7a8dcd9-e40c-4458-8acf-2c47d97c23f4"},"source":["# Evaluation on test sequences\n","print('Test:')\n","evaluate_model(model, rus_tokenizer, X_test, test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Test:\n","Predictions are done. Calculating the scores now\n","src=[tom is very good], target=[том очень хороший], predicted=[том очень хороший]\n","src=[i was born in 1960], target=[я родился в 1960], predicted=[я родился в тысяча девятьсот девятьсот втором втором]\n","src=[do you work in boston], target=[вы работаете в бостоне], predicted=[ты работаешь в бостоне]\n","src=[look at this picture], target=[посмотрите на эту картинку], predicted=[посмотрите на эту фотографию]\n","src=[theres a problem], target=[есть проблема], predicted=[есть проблема]\n","src=[tom is my neighbor], target=[том  мой сосед], predicted=[том мой сосед]\n","src=[wasnt he your friend], target=[он разве не был тебе другом], predicted=[том том не мой друг]\n","src=[i was playing here], target=[я здесь играл], predicted=[я очень здесь]\n","src=[its good to dream], target=[мечтать хорошо], predicted=[это бомба сон]\n","src=[come by tomorrow], target=[заходи завтра], predicted=[приходите завтра]\n","BLEU-4: 0.074475\n","GLEU-4: 0.026248\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LlSKrP3FXlui","executionInfo":{"status":"ok","timestamp":1612874126077,"user_tz":-180,"elapsed":181793,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":[""],"execution_count":14,"outputs":[]}]}