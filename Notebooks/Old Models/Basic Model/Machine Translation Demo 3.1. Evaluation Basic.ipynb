{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Translation Demo 3.1. Evaluation Basic.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMlG94sBzAyGI0hbIrMT1Z4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bAK5iHy80ZQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871278275,"user_tz":-180,"elapsed":2313,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"5bff8436-34a7-4c41-99e9-64b5807f4d77"},"source":["%tensorflow_version 1.x\n","\n","import pickle as pkl\n","import numpy as np\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from nltk.translate.gleu_score import corpus_gleu\n","\n","import tensorflow.python.keras.backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ACevsnNFA1TU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871279344,"user_tz":-180,"elapsed":517,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"759a8a37-65ee-4608-a032-8b1d7fda9711"},"source":["# Imports for colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dirname = '/content/gdrive/My Drive/Colab Notebooks/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RG06b_PbJhtg"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"m0GlKh3DBDi6"},"source":["## Load clean datasets and tokenizers"]},{"cell_type":"code","metadata":{"id":"zW6TU4P0AGqY","executionInfo":{"status":"ok","timestamp":1612871280428,"user_tz":-180,"elapsed":578,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def load_pickle(filename):\n","    return pkl.load(open(filename, 'rb'))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMuKN-hqBnq3"},"source":["## Compute max length of sentence"]},{"cell_type":"code","metadata":{"id":"SCIQDZu6Bksw","executionInfo":{"status":"ok","timestamp":1612871281036,"user_tz":-180,"elapsed":506,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def max_length(lines):\n","    return max(len(line.split()) for line in lines)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRivrL77BtI3"},"source":["## Encode and pad sequences"]},{"cell_type":"code","metadata":{"id":"Hy74uoFxBpvG","executionInfo":{"status":"ok","timestamp":1612871281863,"user_tz":-180,"elapsed":717,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def encode_sequences(tokenizer, length, lines):\n","    # Encode sequences\n","    X = tokenizer.texts_to_sequences(lines)\n","\n","    # Pad sequences with zeros\n","    X = pad_sequences(X, maxlen=length, padding='post')\n","\n","    return X"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cUj8IbOFWeF"},"source":["## Generate a translation from a sequence\n","Algorithm predicts a one-hot encodings of words in a batch of sentences, which can be converted to sequences of numbers of words in a dictionary, which eventually will be converted to sequences of words"]},{"cell_type":"code","metadata":{"id":"4MA2-1FqBvjX","executionInfo":{"status":"ok","timestamp":1612871282529,"user_tz":-180,"elapsed":582,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def batch_generator(sources, batch_size):\n","    for i in range(0, sources.shape[0], batch_size):\n","        yield sources[i:i + batch_size, :]\n","\n","def predict_texts(model, tokenizer, sources, batch_size=4096):\n","    integers = np.empty((sources.shape[0], model.layers[-1].output_shape[1]))\n","    if batch_size==None:\n","        predictions = model.predict(sources, verbose=0, use_multiprocessing=True)\n","        integers = np.argmax(predictions, axis=2)\n","    else:\n","        for idx, batch in enumerate(batch_generator(sources, batch_size)):\n","            actual_batch_len = batch.shape[0]\n","            predictions = model.predict(batch, verbose=0, use_multiprocessing=True)\n","            integers[idx*batch_size:idx*batch_size + actual_batch_len] = np.argmax(predictions, axis=2)\n","    target = tokenizer.sequences_to_texts(integers)\n","    return target"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEwSSPEDJeoR"},"source":["## Evaluate the model"]},{"cell_type":"code","metadata":{"id":"O7CquIilGmRn","executionInfo":{"status":"ok","timestamp":1612871283415,"user_tz":-180,"elapsed":500,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def evaluate_model(model, tokenizer, sources, raw_dataset, batch_size=4096):\n","    actual = [raw_target.split() for raw_target in raw_dataset[:, 1]]\n","    predicted = predict_texts(model, tokenizer, sources, batch_size)\n","    print('Predictions are done. Calculating the scores now')\n","    predicted = [text.split() for text in predicted]\n","    for i in range(10):\n","        print('src=[%s], target=[%s], predicted=[%s]' % (raw_dataset[i, 0], raw_dataset[i, 1], ' '.join(predicted[i])))\n","    # Calculate BLEU score. n-gram (n is up to 4) count weights are 0.25\n","    smoothing = SmoothingFunction()\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, smoothing_function=smoothing.method4))\n","    # Calculate GLEU score. Maximum n-gram length count - 4\n","    print('GLEU-4: %f' % corpus_gleu(actual, predicted))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tl0O4nsYOTPw"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"R56c_YdmMEe7","executionInfo":{"status":"ok","timestamp":1612871285818,"user_tz":-180,"elapsed":2055,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["# Load datasets\n","dataset = load_pickle(dirname + 'english-russian-100k-both.pkl')\n","train = load_pickle(dirname + 'english-russian-100k-train.pkl')\n","test = load_pickle(dirname + 'english-russian-100k-test.pkl')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq7arF4mOb1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871285820,"user_tz":-180,"elapsed":1654,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"342fda00-8805-4838-e741-975ba980fe53"},"source":["# Load english tokenizer\n","eng_tokenizer = load_pickle(dirname + 'en_tokenizer_100k')\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1 #+1 because of <EOS> token\n","eng_length = max_length(dataset[:, 0])\n","print('English vocabulary size: %d' % eng_vocab_size)\n","print('English max sentence length: %d' % eng_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["English vocabulary size: 7313\n","English max sentence length: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O_l51gJkO0lu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871286070,"user_tz":-180,"elapsed":1472,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"4c364486-3420-4ada-a1fb-27813fabf136"},"source":["# Load russian tokenizer\n","rus_tokenizer = load_pickle(dirname + 'ru_tokenizer_100k')\n","rus_vocab_size = len(rus_tokenizer.word_index) + 1\n","rus_length = max_length(dataset[:, 1])\n","print('Russian vocabulary size: %d' % rus_vocab_size)\n","print('Russian max sentence length: %d' % rus_length)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Russian vocabulary size: 20884\n","Russian max sentence length: 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpmtW6r4O1RW","executionInfo":{"status":"ok","timestamp":1612871287435,"user_tz":-180,"elapsed":2340,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["#Encode sequences\n","X_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n","X_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3l8mrInPEKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871290481,"user_tz":-180,"elapsed":4936,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"e33f2c10-9941-4aea-dc25-eca96930d07e"},"source":["# Load model\n","K.clear_session()\n","model = load_model(dirname + 'model_basic_100k_100e.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8oQLLV-PJnO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871379299,"user_tz":-180,"elapsed":93085,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"6c8bdee1-d4df-4d80-edd7-141e9abe730a"},"source":["# Evaluation on training sequences\n","print('Train:')\n","evaluate_model(model, rus_tokenizer, X_train, train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train:\n","Predictions are done. Calculating the scores now\n","src=[i buried it], target=[я её закопал], predicted=[я её закопал]\n","src=[go and wake up mary], target=[пойди разбуди мэри], predicted=[пойди разбудите мэри]\n","src=[she did a good job], target=[она проделала хорошую работу], predicted=[она проделала хорошую работу]\n","src=[i work at a zoo], target=[я работаю в зоопарке], predicted=[я работаю в зоопарке]\n","src=[i want them], target=[я хочу их], predicted=[я хочу хочу]\n","src=[ive been thinking], target=[я размышляю], predicted=[я думал]\n","src=[we talked about boys], target=[мы говорили о мальчиках], predicted=[мы говорили о мальчиках]\n","src=[is that blood], target=[это кровь], predicted=[это кровь]\n","src=[dont be so selfish], target=[не будь такой эгоисткой], predicted=[не будь таким эгоистками]\n","src=[people are stupid], target=[люди глупы], predicted=[люди глупы]\n","BLEU-4: 0.010189\n","GLEU-4: 0.027326\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bnJR07DLRu9w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612871389102,"user_tz":-180,"elapsed":101568,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"92ee243b-c975-4bf4-8be6-8fc9e6f60fe5"},"source":["# Evaluation on test sequences\n","print('Test:')\n","evaluate_model(model, rus_tokenizer, X_test, test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Test:\n","Predictions are done. Calculating the scores now\n","src=[tom is very good], target=[том очень хороший], predicted=[том очень хороший]\n","src=[i was born in 1960], target=[я родился в 1960], predicted=[я родилась в 1982]\n","src=[do you work in boston], target=[вы работаете в бостоне], predicted=[ты работаешь в бостоне]\n","src=[look at this picture], target=[посмотрите на эту картинку], predicted=[посмотрите на эту фотографию]\n","src=[theres a problem], target=[есть проблема], predicted=[есть есть]\n","src=[tom is my neighbor], target=[том  мой сосед], predicted=[том мой сосед]\n","src=[wasnt he your friend], target=[он разве не был тебе другом], predicted=[он он не свой другом]\n","src=[i was playing here], target=[я здесь играл], predicted=[я играла здесь]\n","src=[its good to dream], target=[мечтать хорошо], predicted=[мечта]\n","src=[come by tomorrow], target=[заходи завтра], predicted=[завтра завтра завтра]\n","BLEU-4: 0.147634\n","GLEU-4: 0.025955\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2wSjNheknsK6"},"source":[""],"execution_count":null,"outputs":[]}]}