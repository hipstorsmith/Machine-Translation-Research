{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Translation Demo 3.4. Evaluation Deep Attention.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMFy9t/mb7G+LwEavdHe8iR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bAK5iHy80ZQy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874946774,"user_tz":-180,"elapsed":2949,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"ec13af75-6567-42ae-e18b-737af1c54c87"},"source":["%tensorflow_version 1.x\n","\n","import pickle as pkl\n","import numpy as np\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.python.keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n","from nltk.translate.gleu_score import corpus_gleu\n","\n","import tensorflow.python.keras.backend as K"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ACevsnNFA1TU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874946777,"user_tz":-180,"elapsed":2946,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"2f85574e-907f-4f08-88ab-aaf4eeca1aa9"},"source":["# Imports for colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dirname = '/content/gdrive/My Drive/Colab Notebooks/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RG06b_PbJhtg"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"m0GlKh3DBDi6"},"source":["## Load clean dataset"]},{"cell_type":"code","metadata":{"id":"zW6TU4P0AGqY","executionInfo":{"status":"ok","timestamp":1612874946780,"user_tz":-180,"elapsed":2944,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def load_pickle(filename):\n","    return pkl.load(open(filename, 'rb'))"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMuKN-hqBnq3"},"source":["## Compute max length of sentence"]},{"cell_type":"code","metadata":{"id":"SCIQDZu6Bksw","executionInfo":{"status":"ok","timestamp":1612874946782,"user_tz":-180,"elapsed":2943,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def max_length(lines):\n","    return max(len(line.split()) for line in lines)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRivrL77BtI3"},"source":["## Encode and pad sequences"]},{"cell_type":"code","metadata":{"id":"Hy74uoFxBpvG","executionInfo":{"status":"ok","timestamp":1612874946783,"user_tz":-180,"elapsed":2941,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def encode_sequences(tokenizer, length, lines):\n","    # Encode sequences\n","    X = tokenizer.texts_to_sequences(lines)\n","\n","    # Pad sequences with zeros\n","    X = pad_sequences(X, maxlen=length, padding='post')\n","\n","    return X"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cUj8IbOFWeF"},"source":["## Generate a translation from a sequence\n","Algorithm predicts a one-hot encodings of words in a batch of sentences, which can be converted to sequences of numbers of words in a dictionary, which eventually will be converted to sequences of words"]},{"cell_type":"code","metadata":{"id":"4MA2-1FqBvjX","executionInfo":{"status":"ok","timestamp":1612874946784,"user_tz":-180,"elapsed":2939,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def batch_generator(sources, batch_size=None):\n","    for i in range(0, sources.shape[0], batch_size):\n","        yield sources[i:i + batch_size, :]\n","\n","def predict_texts(model, tokenizer, sources, batch_size=4096):\n","    integers = np.empty((sources.shape[0], model.layers[-1].output_shape[1]))\n","    if batch_size==None:\n","        predictions = model.predict(sources, verbose=0, use_multiprocessing=True)\n","        integers = np.argmax(predictions, axis=2)\n","    else:\n","        for idx, batch in enumerate(batch_generator(sources, batch_size)):\n","            actual_batch_len = batch.shape[0]\n","            predictions = model.predict(batch, verbose=0, use_multiprocessing=True)\n","            integers[idx*batch_size:idx*batch_size + actual_batch_len] = np.argmax(predictions, axis=2)\n","    target = tokenizer.sequences_to_texts(integers)\n","    return target"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEwSSPEDJeoR"},"source":["## Evaluate the model"]},{"cell_type":"code","metadata":{"id":"O7CquIilGmRn","executionInfo":{"status":"ok","timestamp":1612874946784,"user_tz":-180,"elapsed":2936,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["def evaluate_model(model, tokenizer, sources, raw_dataset, batch_size=4096):\n","    actual = [raw_target.split() for raw_target in raw_dataset[:, 1]]\n","    predicted = predict_texts(model, tokenizer, sources, batch_size)\n","    print('Predictions are done. Calculating the scores now')\n","    predicted = [text.split() for text in predicted]\n","    for i in range(10):\n","        print('src=[%s], target=[%s], predicted=[%s]' % (raw_dataset[i, 0], raw_dataset[i, 1], ' '.join(predicted[i])))\n","    # Calculate BLEU score. n-gram (n is up to 4) count weights are 0.25\n","    smoothing = SmoothingFunction()\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, smoothing_function=smoothing.method5))\n","    # Calculate GLEU score. Maximum n-gram length count - 4\n","    print('GLEU-4: %f' % corpus_gleu(actual, predicted))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tl0O4nsYOTPw"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"R56c_YdmMEe7","executionInfo":{"status":"ok","timestamp":1612874951355,"user_tz":-180,"elapsed":7505,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["# Load datasets\n","dataset = load_pickle(dirname + 'english-russian-100k-both.pkl')\n","train = load_pickle(dirname + 'english-russian-100k-train.pkl')\n","test = load_pickle(dirname + 'english-russian-100k-test.pkl')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jq7arF4mOb1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874951841,"user_tz":-180,"elapsed":7988,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"96ecbce7-4808-40f8-8bd3-aa614fa20ff5"},"source":["# Prepare english tokenizer\n","eng_tokenizer = load_pickle(dirname + 'en_tokenizer_100k')\n","eng_vocab_size = len(eng_tokenizer.word_index) + 1 #+1 because of <EOS> token\n","eng_length = max_length(dataset[:, 0])\n","print('English vocabulary size: %d' % eng_vocab_size)\n","print('English max sentence length: %d' % eng_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["English vocabulary size: 7313\n","English max sentence length: 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O_l51gJkO0lu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874952307,"user_tz":-180,"elapsed":8450,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"828eeb5a-6116-42a9-a3d7-bc36fbcda316"},"source":["# Prepare russian tokenizer\n","rus_tokenizer = load_pickle(dirname + 'ru_tokenizer_100k')\n","rus_vocab_size = len(rus_tokenizer.word_index) + 1\n","rus_length = max_length(dataset[:, 1])\n","print('Russian vocabulary size: %d' % rus_vocab_size)\n","print('Russian max sentence length: %d' % rus_length)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Russian vocabulary size: 20884\n","Russian max sentence length: 11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpmtW6r4O1RW","executionInfo":{"status":"ok","timestamp":1612874953828,"user_tz":-180,"elapsed":9967,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":["#Encode sequences\n","X_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n","X_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3l8mrInPEKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612874969436,"user_tz":-180,"elapsed":25571,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"a7f2bd53-1015-477e-9042-437f41896584"},"source":["# Load model\n","K.clear_session()\n","model = load_model(dirname + 'model_deep_attention_do_rdo_100k_100e.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8oQLLV-PJnO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612875168305,"user_tz":-180,"elapsed":224435,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"346bb691-0957-45ac-df5d-9fbf0b843571"},"source":["# Evaluation on training sequences\n","print('Train:')\n","evaluate_model(model, rus_tokenizer, X_train, train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train:\n","Predictions are done. Calculating the scores now\n","src=[i buried it], target=[я её закопал], predicted=[я его закопал]\n","src=[go and wake up mary], target=[пойди разбуди мэри], predicted=[пойди разбуди мэри]\n","src=[she did a good job], target=[она проделала хорошую работу], predicted=[она проделала хорошую работу]\n","src=[i work at a zoo], target=[я работаю в зоопарке], predicted=[я работаю в зоопарке]\n","src=[i want them], target=[я хочу их], predicted=[я хочу их]\n","src=[ive been thinking], target=[я размышляю], predicted=[я размышляю]\n","src=[we talked about boys], target=[мы говорили о мальчиках], predicted=[мы говорили о мальчиках]\n","src=[is that blood], target=[это кровь], predicted=[это кровь]\n","src=[dont be so selfish], target=[не будь такой эгоисткой], predicted=[не будь такими эгоисткой]\n","src=[people are stupid], target=[люди глупы], predicted=[люди глупы]\n","BLEU-4: 0.074449\n","GLEU-4: 0.026450\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bnJR07DLRu9w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612875190212,"user_tz":-180,"elapsed":246338,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}},"outputId":"4781e114-0706-4150-9af7-2857c8cd7269"},"source":["# Evaluation on test sequences\n","print('Test:')\n","evaluate_model(model, rus_tokenizer, X_test, test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Test:\n","Predictions are done. Calculating the scores now\n","src=[tom is very good], target=[том очень хороший], predicted=[том очень хороший]\n","src=[i was born in 1960], target=[я родился в 1960], predicted=[я родился в тысяча тысяча тысяча тысяча]\n","src=[do you work in boston], target=[вы работаете в бостоне], predicted=[вы работаешь в бостоне]\n","src=[look at this picture], target=[посмотрите на эту картинку], predicted=[посмотрите на эту картину]\n","src=[theres a problem], target=[есть проблема], predicted=[существует проблема]\n","src=[tom is my neighbor], target=[том  мой сосед], predicted=[том мой сосед]\n","src=[wasnt he your friend], target=[он разве не был тебе другом], predicted=[он был не не другом]\n","src=[i was playing here], target=[я здесь играл], predicted=[я играл здесь]\n","src=[its good to dream], target=[мечтать хорошо], predicted=[это сон сон]\n","src=[come by tomorrow], target=[заходи завтра], predicted=[завтра завтра завтра]\n","BLEU-4: 0.073812\n","GLEU-4: 0.025487\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LlSKrP3FXlui","executionInfo":{"status":"ok","timestamp":1612875190214,"user_tz":-180,"elapsed":246338,"user":{"displayName":"Hipstor Smith","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ5Qlw9fFblRp_WKe8Ibhe1sTDUOCkg26c8Del5g=s64","userId":"14900987774726866403"}}},"source":[""],"execution_count":14,"outputs":[]}]}